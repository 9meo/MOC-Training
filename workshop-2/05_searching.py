#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
searching_and_querying_05.py
‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ RAG system ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ query engines ‡πÅ‡∏•‡∏∞ retrievers ‡∏ï‡πà‡∏≤‡∏á‡πÜ
"""

from llama_index.core import VectorStoreIndex, Document, Settings
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.indices.postprocessor import SimilarityPostprocessor, KeywordNodePostprocessor
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core.node_parser import SentenceSplitter
import time
import pandas as pd
from typing import List, Dict

def setup_models():
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
    embed_model = HuggingFaceEmbedding(
        model_name="BAAI/bge-m3",
        max_length=8192,
        normalize=True
    )
    Settings.embed_model = embed_model
    print("‚úÖ Models loaded successfully")
    return embed_model

def create_documents():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"""
    documents = [
        Document(
            text="""
            ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (Machine Learning) ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
            ‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏°‡∏µ‡∏™‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å ‡∏Ñ‡∏∑‡∏≠ Supervised Learning ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö
            Unsupervised Learning ‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏û‡∏ó‡πÄ‡∏ó‡∏¥‡∏£‡πå‡∏ô‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö ‡πÅ‡∏•‡∏∞ Reinforcement Learning ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
            ‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ä‡πâ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà Linear Regression, Decision Trees, Random Forest, Support Vector Machines ‡πÅ‡∏•‡∏∞ Neural Networks
            """,
            metadata={"topic": "machine_learning", "difficulty": "beginner"}
        ),
        Document(
            text="""
            Deep Learning ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á Machine Learning ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô (Deep Neural Networks)
            ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà CNN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û RNN ‡πÅ‡∏•‡∏∞ LSTM ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡πÅ‡∏•‡∏∞ Transformer 
            ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô Deep Learning ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏π‡∏á
            """,
            metadata={"topic": "deep_learning", "difficulty": "intermediate"}
        ),
        Document(
            text="""
            Natural Language Processing (NLP) ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå ‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå
            ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå ‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô NLP ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ Text Classification
            Named Entity Recognition (NER) Sentiment Analysis Machine Translation Question Answering ‡πÅ‡∏•‡∏∞ Text Summarization
            ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏™‡∏°‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ä‡πâ Pre-trained Language Models ‡πÄ‡∏ä‡πà‡∏ô BERT GPT ‡πÅ‡∏•‡∏∞ T5 ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
            """,
            metadata={"topic": "nlp", "difficulty": "intermediate"}
        ),
        Document(
            text="""
            Retrieval-Augmented Generation (RAG) ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° Information Retrieval ‡πÅ‡∏•‡∏∞ Text Generation ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
            ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡∏Ñ‡∏∑‡∏≠ Retriever ‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ ‡πÅ‡∏•‡∏∞ Generator ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
            ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
            ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ similarity ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏≥‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô context ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ Language Model
            RAG ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î hallucination ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á AI ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
            """,
            metadata={"topic": "rag", "difficulty": "advanced"}
        )
    ]
    return documents

def create_index(documents):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á index ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"""
    parser = SentenceSplitter(chunk_size=400, chunk_overlap=50)
    nodes = parser.get_nodes_from_documents(documents)
    index = VectorStoreIndex(nodes)
    print(f"üìö Created index with {len(nodes)} nodes from {len(documents)} documents")
    return index, nodes

def test_basic_query_engine(index, queries):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö Basic Query Engine"""
    print("\nüîç Testing Basic Query Engine:")
    print("=" * 40)
    
    query_engine = index.as_query_engine(similarity_top_k=3, response_mode="compact")
    results = []
    
    for i, query in enumerate(queries, 1):
        print(f"\nQuery {i}: {query}")
        print("-" * 40)
        
        try:
            start_time = time.time()
            response = query_engine.query(query)
            end_time = time.time()
            
            result = {
                "query": query,
                "response": str(response),
                "response_time": end_time - start_time,
                "source_nodes": len(response.source_nodes) if hasattr(response, 'source_nodes') else 0
            }
            results.append(result)
            
            print(f"Answer: {str(response)[:200]}...")
            print(f"Time: {end_time - start_time:.3f}s")
            
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")
            results.append({
                "query": query,
                "response": f"Error: {str(e)}",
                "response_time": 0,
                "source_nodes": 0
            })
    
    return results

def test_response_modes(index, query):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö Response Modes ‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    print(f"\nüìù Testing Response Modes with: {query}")
    print("=" * 50)
    
    modes = ["compact", "refine", "tree_summarize", "simple_summarize"]
    results = []
    
    for mode in modes:
        try:
            print(f"\nüîÑ Testing {mode} mode:")
            
            query_engine = index.as_query_engine(
                similarity_top_k=3,
                response_mode=mode
            )
            
            start_time = time.time()
            response = query_engine.query(query)
            end_time = time.time()
            
            result = {
                "mode": mode,
                "response": str(response),
                "response_time": end_time - start_time,
                "response_length": len(str(response))
            }
            results.append(result)
            
            print(f"Response ({len(str(response))} chars): {str(response)[:150]}...")
            print(f"Time: {end_time - start_time:.3f}s")
            
        except Exception as e:
            print(f"‚ùå Error with {mode}: {str(e)}")
            results.append({
                "mode": mode,
                "response": f"Error: {str(e)}",
                "response_time": -1,
                "response_length": 0
            })
    
    return results

def test_advanced_query_engine(index, queries):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö Advanced Query Engine"""
    print("\n‚ö° Testing Advanced Query Engine:")
    print("=" * 40)
    
    try:
        # Create custom retriever
        retriever = VectorIndexRetriever(index=index, similarity_top_k=5)
        
        # Add postprocessors
        postprocessors = [
            SimilarityPostprocessor(similarity_cutoff=0.6),
            KeywordNodePostprocessor(keywords=["machine learning", "deep learning"], exclude_keywords=[])
        ]
        
        # Create advanced query engine
        query_engine = index.as_query_engine(similarity_top_k=5)  # Fallback to basic
        
    except Exception as e:
        print(f"‚ö†Ô∏è Advanced features not available: {str(e)}")
        print("Using basic query engine instead...")
        query_engine = index.as_query_engine(similarity_top_k=5)
    
    results = []
    for i, query in enumerate(queries, 1):
        print(f"\nAdvanced Query {i}: {query}")
        print("-" * 40)
        
        try:
            start_time = time.time()
            response = query_engine.query(query)
            end_time = time.time()
            
            source_info = []
            if hasattr(response, 'source_nodes'):
                for node in response.source_nodes:
                    source_info.append({
                        "score": getattr(node, 'score', 0),
                        "topic": node.metadata.get('topic', 'unknown'),
                        "text_preview": node.text[:100] + "..."
                    })
            
            result = {
                "query": query,
                "response": str(response),
                "response_time": end_time - start_time,
                "sources": source_info
            }
            results.append(result)
            
            print(f"Answer: {str(response)[:200]}...")
            print(f"Sources: {len(source_info)} nodes")
            print(f"Time: {end_time - start_time:.3f}s")
            
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")
            results.append({
                "query": query,
                "response": f"Error: {str(e)}",
                "response_time": 0,
                "sources": []
            })
    
    return results

def compare_configurations(index, queries):
    """‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    print("\nüìä Comparing Query Engine Configurations:")
    print("=" * 50)
    
    configs = [
        {"name": "Basic", "similarity_top_k": 3, "response_mode": "compact"},
        {"name": "High Recall", "similarity_top_k": 7, "response_mode": "tree_summarize"},
        {"name": "Precise", "similarity_top_k": 2, "response_mode": "compact"},
        {"name": "Fast", "similarity_top_k": 3, "response_mode": "simple_summarize"}
    ]
    
    all_results = []
    
    for config in configs:
        print(f"\nüîß Testing {config['name']} configuration:")
        
        for query in queries[:2]:  # Test with first 2 queries only
            try:
                query_engine = index.as_query_engine(
                    similarity_top_k=config['similarity_top_k'],
                    response_mode=config['response_mode']
                )
                
                start_time = time.time()
                response = query_engine.query(query)
                end_time = time.time()
                
                all_results.append({
                    "config": config['name'],
                    "query": query[:50] + "...",
                    "response_time": end_time - start_time,
                    "response_length": len(str(response)),
                    "similarity_top_k": config['similarity_top_k'],
                    "response_mode": config['response_mode']
                })
                
                print(f"  Query: {query[:50]}...")
                print(f"  Time: {end_time - start_time:.3f}s, Length: {len(str(response))} chars")
                
            except Exception as e:
                print(f"  ‚ùå Error: {str(e)}")
    
    return all_results

def analyze_performance(results):
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"""
    if not results:
        print("No results to analyze")
        return
    
    df = pd.DataFrame(results)
    
    print("\nüìà Performance Analysis:")
    print("=" * 30)
    
    if 'config' in df.columns:
        # Group by configuration
        summary = df.groupby('config').agg({
            'response_time': ['mean', 'std'],
            'response_length': ['mean', 'std']
        }).round(3)
        
        print("Performance Summary by Configuration:")
        print(summary)
    else:
        # Overall statistics
        print(f"Total queries: {len(df)}")
        print(f"Average response time: {df['response_time'].mean():.3f}s")
        print(f"Average response length: {df['response_length'].mean():.0f} chars")

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞ querying"""
    print("=" * 60)
    print("üîç SEARCHING AND QUERYING WITH RAG")
    print("=" * 60)
    
    try:
        # 1. Setup
        print("\n1Ô∏è‚É£ Setting up models...")
        embed_model = setup_models()
        
        # 2. Create documents and index
        print("\n2Ô∏è‚É£ Creating documents and index...")
        documents = create_documents()
        index, nodes = create_index(documents)
        
        # 3. Test queries
        test_queries = [
            "Machine Learning ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á?",
            "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á CNN ‡πÅ‡∏•‡∏∞ RNN ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?",
            "RAG ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?",
            "NLP ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?"
        ]
        
        # 4. Basic query engine test
        print("\n3Ô∏è‚É£ Testing Basic Query Engine...")
        basic_results = test_basic_query_engine(index, test_queries)
        
        # 5. Response modes test
        print("\n4Ô∏è‚É£ Testing Response Modes...")
        mode_results = test_response_modes(
            index, 
            "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Machine Learning ‡πÅ‡∏•‡∏∞ Deep Learning"
        )
        
        # 6. Advanced query engine test
        print("\n5Ô∏è‚É£ Testing Advanced Query Engine...")
        advanced_results = test_advanced_query_engine(index, test_queries[:2])
        
        # 7. Configuration comparison
        print("\n6Ô∏è‚É£ Comparing Configurations...")
        comparison_results = compare_configurations(index, test_queries)
        
        # 8. Performance analysis
        print("\n7Ô∏è‚É£ Performance Analysis...")
        analyze_performance(basic_results)
        if comparison_results:
            analyze_performance(comparison_results)
        
        # 9. Summary
        print("\n" + "=" * 60)
        print("üìã SUMMARY - Searching and Querying Strategies")
        print("=" * 60)
        print("\n‚úÖ Query Engine Types:")
        print("1. Basic Query Engine: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ")
        print("2. Advanced Query Engine: ‡πÉ‡∏ä‡πâ postprocessors ‡πÅ‡∏•‡∏∞ filters")
        print("\n‚úÖ Response Modes:")
        print("- compact: ‡∏£‡∏ß‡∏° context ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÄ‡∏£‡πá‡∏ß)")
        print("- refine: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö iterative (‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥)")
        print("- tree_summarize: ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ (‡∏™‡∏°‡∏î‡∏∏‡∏•)")
        print("- simple_summarize: ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡πÄ‡∏£‡πá‡∏ß)")
        print("\n‚úÖ Best Practices:")
        print("- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å similarity_top_k ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (3-8 nodes)")
        print("- ‡∏õ‡∏£‡∏±‡∏ö response_mode ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£")
        print("- ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î")
        print("- ‡πÉ‡∏ä‡πâ metadata ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö")
        
        print("\nüéâ Searching and Querying demo completed successfully!")
        
        return {
            "index": index,
            "basic_results": basic_results,
            "mode_results": mode_results,
            "advanced_results": advanced_results,
            "comparison_results": comparison_results
        }
        
    except Exception as e:
        print(f"‚ùå Error in demo: {str(e)}")
        return None

if __name__ == "__main__":
    results = main()